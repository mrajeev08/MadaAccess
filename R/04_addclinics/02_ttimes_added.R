# ------------------------------------------------------------------------------------------------ #
#' Incrementally adding clinics based on travel times
#'  Getting travel time estimates and catchments for districts/communes as clinics are added
#'   Code should be run in parallel with shared memory if large input cand_mat
#'   On the Della cluster at Princeton with 18 cores, it takes approximately 1 hr 10 minutes; 
#'   On MacOS with 16 GB 1867 MHz DDR3 and 2.9 GHz Intel Core i5 with three cores, 
#'   it takes approximately 10 hours
# ------------------------------------------------------------------------------------------------ #

# Pull in command line arguments on how to run this script
args <- commandArgs(trailingOnly = TRUE)
type <- args[1]
cores <- args[2]

if(type == "local") {
  library(doParallel)
  cl <- makeCluster(detectCores() - 1, type = "FORK")
  registerDoParallel(cl)
} 

if(type == "remote") {
  # set up cluster on single node with do Parallel
  library(doParallel) 
  cl <- makeCluster(cores)
  registerDoParallel(cl)
  Sys.time()
}

if(type == "serial") {
  print("Warning: will run without parallel backend")
}

# Libraries
library(foreach)
library(tidyverse)
library(iterators)
library(data.table)

# Source
source("R/functions/out.session.R")
source("R/functions/ttime_functions.R")

# Pull in candidates
cand_mat <- fread("/scratch/gpfs/mrajeev/output/ttimes/candidate_matrix.gz") # this is a huge file!
candidate_ids <- 1:nrow(cand_mat) + 31

## Baseline df
base_df <- fread("output/ttimes/baseline_grid.gz")

## Do the candidates
system.time ({
  add.armc(base_df = base_df, clinic_names = candidate_ids, clinic_catchmat = cand_mat, 
           max_clinics = ncol(cand_mat), thresh_ttimes = 3*60, thresh_prop = 1e-4, 
           dir_name = "/scratch/gpfs/mrajeev/output/ttimes/addclinics_")
})

# Close out 
file_path <- "R/04_addclinics/02_ttimes_added.R"

if(type == "serial") {
  print("Done serially:)")
  out.session(path = file_path, filename = "output/log_local.csv")
} 

if(type == "local") {
  stopCluster(cl)
  print("Done locally:)")
  out.session(path = file_path, filename = "output/log_local.csv")
} 

if (type == "remote") {
  out.session(path = file_path, filename = "output/log_cluster.csv")
  closeCluster(cl)
  mpi.quit()
  print("Done remotely:)")
  Sys.time()
}