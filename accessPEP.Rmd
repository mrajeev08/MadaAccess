---
title: "Estimating Access to Rabies Post-Exposure Prophylaxis in Madagascar"
author: ""
date: 
output:
  html_document: default
  pdf_document:
    includes:
      in_header: mystyle.sty
  word_document:
    reference_docx: format_docs/word_styles_reference_01.docx
---


```{r directory, echo = FALSE, message = FALSE, warning = FALSE, results = 'hide'}
## Libraries
library(data.table)
library(knitr)
library(RImagePalette)
library(jpeg)
library(tidyverse)
library(lubridate)
library(magrittr)
library(rgdal)
library(broom)
library(stringr)
library(ISOweek)
library(raster)
library(sp)
library(MASS)
library(reshape2)
source("R/utils.R")

select <- dplyr::select
knitr::opts_chunk$set(fig.pos = 'h', echo = FALSE, message = FALSE, warning = FALSE, 
                      results = "hide",
                      include = TRUE)
```

## INTRODUCTION

Deaths due to canine mediated rabies, estimated to cause approximately 60,000 human deaths anually, can be prevented through prompt administration of post-exposure prophylaxis. However, access to this intervention is highly limited in areas where the disease is endemic (*cite GAVI paper or Nandini's paper of geographic availability of PEP*). Data on true rabies exposures in humans and incidence in animals is also lacking in most of these countries, with the most commonly available data being numbers of bite victims reporting to health facilities. 

Here--discuss geographic variation in access to vaccination and care--how this shapes mortality for other diseases. 

The majority of rabies burden studies use these data to estimate burden from probability decision tree frameworks, often with the key assumption that overall reported bite incidence (i.e. both bites due to non-rabid and rabid animals) are proportional to rabies incidence (i.e. the more bites reported in a location, the higher the incidence of *rabies* exposures there) and that reporting is uniform across space. While at the national level these estimates may be accurate, at the sub-national level, this framework will likely underestimate rabies deaths in places with low reporting and overestimate rabies deaths in places with high reporting of bites. The most recent estimation of burden and the impact of PEP used another approach, using transmission dynamic models as the backbone to predict incidence based on the level of vaccination coverage and size of the dog population at the national level. Using transmission dynamic models to estimate incidence could improve upon previous studies which may underestimate rabies burden in areas with low reporting.

In Madagascar, Institut Pasteur de Madagascar (IPM) provides PEP at no-cost to patients at 31 clinics across the country. PEP is not available at any other public clinics or through the private sector. In addition, there is limited control in dog populations and the disease is endemic throughout the country. Due to the spatially restricted nature of PEP, geographic access is likely to be a major driver of disease burden within the country. To get spatial estimates of disease burden in this context, we flip the standard decision tree and make the assumption that reported bite incidence reflects access to PEP rather than differences in rabies incidence, using travel times to clinics as a predictor of reported bites. Then using a range of rabies incidence given endemic transmission with no mass dog vaccination (*GAVI paper*), we generate sub-national estimates of rabies burden in an adapted decision tree framework. Finally, using this same model pipeline, we explore the impacts of geographically expanding access to PEP in Madagascar on reducing human rabies deaths.   


## METHODS

### GIS Data
We used the global friction surface for 2015 generated by the Malaria Atlas Project ( https://map.ox.ac.uk/research-project/accessibility_to_cities/, Weiss et al. 2015,) and GPS points of clinics to estimate the travel time to the nearest ARMC for the country of Madagascar at a 1 x 1 km scale. We then calculated a weighted average of travel times by human population to the commune level, using administrative shapefiles available trhough the UN Office for the Coordination of Humanitarian Affairs. Human population estimates were taken from the 2015 UN adjusted population projections from World Pop (www.worldpop.org, Linaird et al. 2012) and also aggreagated to the commune level.

<br>

```{r get data}
## read in data
ctar_data <- read.csv("data/SaisieRage_DATA_2018-09-21_1755.csv")
ctar_metadata <- read.csv("data/ctar_metadata.csv")
mada_district <- readOGR("data/MadaGIS/MadaPops.shp")
mada_communes <- readOGR("output/communes/communes_extracted.shp")

## catchment data
dist_catchments <- read.csv("output/catchments_district_unmasked.csv", row.names = 1)
names(dist_catchments) <- c("mdg_dis_co", "CTAR", "ttimes_weighted")
comm_catchments <- read.csv("output/catchments_commune_unmasked.csv", row.names = 1)
names(comm_catchments) <- c("mdg_cm_", "CTAR", "ttimes_weighted")

## Centers with no data ## Change this to be so that only ones with zero forms!
no_data <- c("IPM", "Fianarantsoa", "Ambatomainty", "Ambovombe Androy", "Tsiroanomandidy", 
             "Taolagnaro", "Mandritsara", 
             "Antsiranana", "Marolambo", "Nosy be", "Sainte Marie", "Vangaindrano")
ctar_metadata$exclude <- 0
ctar_metadata$exclude[ctar_metadata$CTAR %in% no_data] <- 1

## Getting ctar district and commune
ctar_metadata$ctar_dist <- mada_district$mdg_dis_co[match(ctar_metadata$District, 
                                                           mada_district$district)]
pts <- SpatialPoints(cbind(ctar_metadata$LONGITUDE, ctar_metadata$LATITUDE), 
                   proj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
ctar_metadata$ctar_comm <- over(pts, mada_communes)$mdg_cm_
dist_catchments$ctar_in_dist <- ifelse(dist_catchments$mdg_dis_co %in% ctar_metadata$ctar_dist, 1, 0)
comm_catchments$ctar_in_comm <- ifelse(comm_catchments$mdg_cm_ %in% ctar_metadata$ctar_comm, 1, 0)

## Get color palette from other network fig!
ctar_metadata$color <- c("#FCC56F","#FFDBE5", "#7A4900", "#CBCDD2", "#0000A6", "#EFF2F1",
                 "#99d8c9", "#B79762", "#004D43", "#8FB0FF", "#997D87", "#FD9C54", "#8362B5",
                 "#578FB0","#5A0007", "#809693", "#D16100", "#1B4400", "#4FC601", "#3B5DFF", 
                 "#4A3B53", "#FF2F80","#61615A", "#BA0900", "#6B7900", "#00C2A0", "#FFAA92",
                 "#FF90C9", "#B903AA", "#FEFFE6", "#E9E9D2")
ctar_metadata$color[ctar_metadata$CTAR %in% no_data] <- "#D3D3D3"
ctar_metadata$fill <- ctar_metadata$color
ctar_metadata$fill <- add.alpha(ctar_metadata$fill, 0.4)
# display_palette(ctar_metadata$color)

dist_catchments %>% left_join(select(ctar_metadata, CTAR, exclude, 
                                     color, fill, ctar_dist, LATITUDE, LONGITUDE)) -> dist_catchments
mada_district@data <- left_join(mada_district@data, dist_catchments) ## need this?

## Getting commune covars
## Need: weighted ttimes, pop, ctar_in, exclude
comm_catchments %>%
  left_join(select(mada_communes@data, pop = MDG__201, mdg_cm_, district = mtch_ds)) %>%
  left_join(select(mada_district@data, mdg_dis_co, district, ctar_in_dist, dist_catch = CTAR, exclude,
                   color, fill, ctar_dist)) -> comm_data
comm_data <- filter(comm_data, ttimes_weighted != "Inf")

# ## Data to include
# nrow(dist_catchments) - sum(dist_catchments$exclude)
# nrow(comm_data) - sum(comm_data$exclude)

#### Moramanga data! ###
## ctar for # bites and also checking days to rule out contacts
col_lookup <- read.csv("data/new_colnames.csv", header = TRUE)
ctar <- read.csv("data/moramanga/ctar_up_todate.csv", header = TRUE)
ctar <- match.colnames(ctar, subset(col_lookup, form == "ctar"))

## Set-up time series
tfunc <- function (date, format_date = "%Y-%m-%d", start = "01-09-2016", format_start = "%d-%m-%Y",
                   year1 = 2016, tstep = "month", period = FALSE) {
  get.consec (date, format_date, start, format_start,
              year1, tstep, period) - 8 ## starts in Sep
}

## all dates
ctar %>%
  mutate_at(vars(starts_with("date")), funs(dmy(.))) -> ctar
ctar$month <- tfunc(ctar$date.reported)
## subset to study period (Sep 2016 - to date)
## checks for cases where month is NA!
ctar <- subset(ctar, month > 0 & month < 28)

# ctar district and commune
ctar$commune <- sapply(strsplit(as.character(ctar$patient.location), "\\("), "[", 1)
ctar$commune <- trimws(ctar$commune, which = "right")
ctar$district <- sapply(strsplit(as.character(ctar$patient.location), "\\, "), "[", 2)
ctar$district <- gsub(" \\(District\\)", "", ctar$district)

## change all true/false to 0/1
ctar[ctar == FALSE] <- 0

## Bite data in Moramanga
n_months <- max(ctar$month, na.rm = TRUE)

ctar %>%
  left_join(select(mada_communes@data, commune, mdg_cm_, mtch_ds), 
            by = c("commune" = "commune", "district" = "mtch_ds")) %>%
  filter(consult.type == "Animal bite/exposure") %>%
  group_by(mdg_cm_) %>%
  summarize(bites = round(n()/n_months*12)) %>%
  left_join(comm_data) %>%
  filter(!is.na(ttimes_weighted), 
         district %in% mada_district@data$district[mada_district@data$CTAR == "Moramanga"]) -> mora_bites
```

<br>


### Bite patient data
We used a database of bite patient forms submitted to IPM from ARMC across the country between 2014 - 2017. These were individual patient data forms that were submitted as frequently as monthly to annually by clinics. Of the 31 existing ARMC, `r length(no_data) - 2` submitted fewer than 10 forms over the four years. Two clinics, the IPM ARMC and the Fianarantsoa ARMC had separate databases which were not available at the time of analysis. Overall, we had data from `r 31 - length(no_data)` clinics across the country (Fig 1A). These data include details of the administrative district of the bite patient's address and the date of reporting. We also had `r max(ctar$month, na.rm = TRUE)` months of data from the Moramanga District that were resolved to the commune level (the administrative level below the district).

<br>

For most districts, the majority of bites were reported to the closest clinic as estimated by our travel time metric (Fig 1A, Fig S1). Therefore, we defined the catchment area for each clinic as all districts for which the clinic was the closest ARMC. We excluded any catchment areas for which the clinic did not submit any forms (n = `r length(no_data)`, districts in grey in Fig 1A).

```{r network fig}
## Network fig
## Revise: points = CTAR points with size proportional to number of bites reported, lines to district proportional to the number of bites from that district, outline = by district, communes = polygons shaded by catchments

## get exposure matrix = first set of points
## district exposures
ctar_data %>% 
  drop_na(id_ctar, district) %>%
  group_by(district) %>% # group by district
  summarize(n = n()) -> exps_dist # get count of exposures
## ctar exposures
ctar_data %>% 
  drop_na(id_ctar) %>%
  group_by(id_ctar) %>% # group by ctar
  summarize(n = n()) -> exps_ctar
## ctar by district exposure matrix
ctar_data %>% 
  drop_na(id_ctar, district) %>%
  group_by(district, id_ctar) %>% # group by district and ctar
  summarize(n = n()) -> exp_mat# get count of exposures

## To plot district bites
dist_points <- cbind(select(mada_district@data,
                            mdg_dis_co), coordinates(mada_district))
names(dist_points)[2:3] <- c("dist_long", "dist_lat")
dist_points %>%
 left_join(select(ctar_metadata, ctar_dist, LATITUDE, LONGITUDE), 
           by = c("mdg_dis_co" = "ctar_dist")) %>%
 mutate(dist_long = coalesce(LONGITUDE, dist_long), 
        dist_lat = coalesce(LATITUDE, dist_lat)) -> dist_points

exps_dist %>%
  right_join(select(dist_points, mdg_dis_co, dist_long, dist_lat),
             by = c("district" = "mdg_dis_co")) %>%
  left_join(dist_catchments, by = c("district" = "mdg_dis_co") ) -> dist_points
dist_points$size <- log(dist_points$n + 0.1)*0.25

## To plot ctar points (only those not excluded)
exps_ctar %>%
 left_join(select(ctar_metadata, id_ctar, LATITUDE, LONGITUDE, 
                  exclude, color, fill)) %>%
 filter(exclude == 0) -> ctar_points

## To plot lines between ctar + districts
exp_mat %>% 
  left_join(select(dist_points, district, dist_long, dist_lat)) %>%
  left_join(select(ctar_metadata, id_ctar, LATITUDE, LONGITUDE,
                   color, fill, ctar_dist)) -> dist_lines
dist_lines$size <- log(dist_lines$n + 0.1)*0.25
```

```{r figure 1A}
jpeg("figs/network.jpeg")
plot(mada_district, col = mada_district$fill, border = "grey") 
segments(dist_lines$dist_long, dist_lines$dist_lat, x1 = dist_lines$LONGITUDE, 
         y1 = dist_lines$LATITUDE,
         lwd = dist_lines$size*2, col = dist_lines$color)
points(ctar_points$LONGITUDE, ctar_points$LATITUDE, col = ctar_points$color, pch = 1,
       cex = log(ctar_points$n + 0.1)*0.25)
points(dist_points$dist_long, dist_points$dist_lat, cex = dist_points$size, pch = 20,
       col = dist_points$color)
legend("topright", c("10", "50", "100", "200", "400", "800", "1600"), pch = 1, xjust = 1, yjust = 1,
       pt.cex = log((c(10, 50, 100, 200, 400, 800, 1600)) + 0.1)*0.25, 
       lwd = log((c(10, 50, 100, 200, 400, 800, 1600)) + 0.1)*0.25, bty = "n", y.intersp = 0.75,
       title = "Number of \n reported bites", xpd = TRUE)
legend("topleft", "A", bty = "n", inset = c(0.2, 0), text.font = 2)
dev.off()
```

```{r network output, echo=FALSE, fig.cap="Figure 1A", results = "show", out.width = '100%'}
knitr::include_graphics("figs/network.jpeg")
```



```{r figure 1b, fig.cap = "Figure 1B"}
exp_mat %>% 
  left_join(select(ctar_metadata, ctar_obs = CTAR, id_ctar)) %>%
  left_join(select(dist_catchments, mdg_dis_co, ctar_catch = CTAR, exclude), 
            by = c("district" = "mdg_dis_co")) %>%
  group_by(district) %>% # group by ctar
  mutate(prop = n/sum(n),
         catch_match = ifelse(ctar_obs == ctar_catch, 1, 0)) %>%
  filter(catch_match == 1) -> catch_dist
hist(catch_dist$prop, main = "", 
     xlab = "Proportion of patients \n reporting to closest ARMC",
     ylab = "Number of districts", col = "grey50", border = "white", xlim = c(0, 1))

exp_mat %>% 
  left_join(select(ctar_metadata, ctar_obs = CTAR, id_ctar)) %>%
  left_join(select(dist_catchments, mdg_dis_co, ctar_catch = CTAR, exclude), 
            by = c("district" = "mdg_dis_co")) %>%
  group_by(ctar_obs) %>% # group by ctar
  mutate(prop = n/sum(n),
         catch_match = ifelse(ctar_obs == ctar_catch, 1, 0)) %>%
  filter(catch_match == 1) %>%
  summarize(prop = sum(prop)) -> catch_ctar
```

```{r figure 1C, fig.cap = "Figure 1C"}
hist(catch_ctar$prop, main = "", 
     xlab = "Proportion of patients reporting from within catchment",
     ylab = "Number of ARMC", col = "grey50", border = "white", xlim = c(0, 1))
```

As even for clinics which submitted data, there was substantial undersubmission of forms, we estimated clinic level reporting as the proportion of days on which forms were submitted, excluding any periods for which there were no forms submitted for 15 consecutive days (Figure S2). Our estimate of reporting did vary based on our assumption of the threshold number of consecutive days (Figure S3), so we did look at the sensitivity of model parameter estimates to changing this threshold. To estimate the average annual bites reported for each district, we further excluded data from any years for which there was less than 25% reporting at the clinic level.

```{r clinic level reporting, fig.cap = "Figure 2A"}
######### Patient time series
ctar_data %>%
  select(id_ctar, date_de_consultation) %>%
  drop_na(id_ctar) %>%
  mutate(date_de_consultation = ymd(date_de_consultation)) %>%
  gather(dose, date_de_consultation, -id_ctar) %>%
  group_by(id_ctar, date_de_consultation) %>%
  summarise(n = n()) -> patient_ts

patient_ts <- patient_ts[!is.na(patient_ts$date_de_consultation), ]
patient_ts$ctar <- ctar_metadata$CTAR[match(patient_ts$id_ctar, ctar_metadata$id_ctar)]
patient_ts <- patient_ts[!is.na(patient_ts$ctar), ]

start_date <- ymd("2014-01-01")
end_date <- ymd("2017-12-31")

## getting reporting
ts <- as_tibble(seq(start_date, end_date, by = "day"))

patient_ts %>%
  right_join(ts, by = c("date_de_consultation" = "value")) %>%
  select(id_ctar, date_de_consultation, n) %>%
  spread(id_ctar, n) %>%
  replace(., is.na(.), 0) -> doses_wide
dose_mat <- as.matrix(doses_wide[, 2:(ncol(doses_wide) - 1)])

get.days <- function(dmat = dose_mat, threshold = 10) {
  date_mat <- matrix(NA, nrow(dmat), ncol(dmat))
  for (j in 1:ncol(date_mat)){
    rle(dmat[ , j]) %>%
      unclass() %>%
      as.data.frame() %>%
      mutate(end = cumsum(lengths),
             start = c(1, lag(end)[-1] + 1)) %>%
      filter(values == 0, lengths >= threshold) -> rles
  if(nrow(rles) > 0){
    for (i in 1:nrow(rles)){
        date_mat[rles$start[i]:rles$end[i], j] <- 0
      }
    }
  }
  
  date_mat <- replace(date_mat, is.na(date_mat), 1)
  date_mat %>% 
    as_tibble() %>%
    group_by(date = year(doses_wide$date_de_consultation)) %>%
    summarise_all(funs(sum(.)/n())) -> clinic_reporting
  colnames(clinic_reporting) <- colnames(doses_wide)[1:(ncol(doses_wide)-1)]

  clinic_reporting <- gather(clinic_reporting, id_ctar, prop, -date_de_consultation)
  clinic_reporting$ctar <- ctar_metadata$CTAR[match(clinic_reporting$id_ctar, 
                                                  ctar_metadata$id_ctar)]
  clinic_reporting$id_ctar <- as.numeric(clinic_reporting$id_ctar)
  clinic_reporting$threshold <- threshold
  return(list(clinic_reporting, date_mat))
}

date_mat <- as.data.frame(get.days(threshold = 15)[[2]])
date_mat$date_de_consultation <- doses_wide$date_de_consultation
date_mat <-melt(date_mat, id = "date_de_consultation")
levels(date_mat$variable) <- names(doses_wide)[2:23]
names(date_mat) <- c("date_de_consultation", "id_ctar", "exclude")

patient_ts %>%
  ungroup() %>%
  mutate(id_ctar = as.factor(id_ctar)) %>%
  right_join(date_mat) %>%
  mutate(n = replace_na(n, 0), 
         n = ifelse(exclude == 1, n, NA)) -> doses_long
doses_long$ctar <- ctar_metadata$CTAR[match(doses_long$id_ctar, ctar_metadata$id_ctar)]

ggplot(data = doses_long, aes(date_de_consultation, ctar)) + 
   geom_tile(aes(fill = n)) +
   scale_fill_gradientn(colours = c("white", "purple", "black"), values = c(0, 0.1, 1),
                        na.value = alpha("lightgrey", 1)) +
   xlim(start_date, end_date)

clinic_reporting <- get.days(threshold = 15)[[1]]

```

```{r figure 1B, fig.cap = "Figure 1B"}
clinic_reporting %>%
  mutate(prop15 = prop, prop5 = get.days(threshold = 5)[[1]]$prop,
         prop30 = get.days(threshold = 30)[[1]]$prop) %>%
  ggplot(., aes(x = reorder(ctar, prop), color = ctar)) +
  geom_hline(yintercept = 0.25, color = "darkgrey") +
  geom_boxplot(aes(ymin = prop30, lower = prop15, middle = prop15, upper = prop15, ymax = prop5),
               stat = "identity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none") +
  xlab("") +
  ylab("Proportion of days included") +
  coord_flip() +
  labs(tag = "B")

```


```{r figure 3B, fig.cap= "Figure 3B"}
patient_ts %>%
  group_by(ctar) %>%
  mutate(exclude = ifelse(n > mean(n) + 3*sd(n), 1, 0)) -> patient_ts

ggplot(data = drop_na(patient_ts, exclude), aes(x = ctar, y = n, color = as.factor(exclude))) +
  scale_color_discrete(name = "Exclude", labels = c("Yes", "No")) +
  ylab("Number of patients per day") +
  geom_jitter(alpha = 0.5, width = 0.25) +
  coord_flip()

to_exclude <- c(grep("contact", unique(ctar_data$remarque), ignore.case = TRUE, value = TRUE),
                grep("contam", unique(ctar_data$remarque), ignore.case = TRUE, value = TRUE),
                grep("consom", unique(ctar_data$remarque), ignore.case = TRUE, value = TRUE),
                grep("passage", unique(ctar_data$remarque), ignore.case = TRUE, value = TRUE))
to_exclude <- to_exclude[-grep("date", to_exclude, ignore.case = TRUE)]
ctar_data$exclude_bycomment <- 0
ctar_data$exclude_bycomment[ctar_data$remarque %in% to_exclude] <- 1
ctar_data <- mutate(ctar_data, date_de_consultation = ymd(date_de_consultation))
patient_ts %>%
  ungroup() %>%
  select(id_ctar, date_de_consultation, exclude_bydate = exclude) %>%
  right_join(ctar_data) -> ctar_check

```


```{r trying to exclude contacts, fig.cap="Figure 3A"}
## Testing with Moramanga data 
sdev <- seq(2, 10, by = 1)
check <- data.frame(sd = NA, prop_bites = NA, prop_contacts = NA)
for (i in 1:length(sdev)){
  ctar %>%
    group_by(date.reported) %>%
    summarize(n = n()) %>%
    mutate(exclude = ifelse(n > mean(n) + sdev[i]*sd(n), 1, 0)) -> mora_ts
  ctar$exclude <-mora_ts$exclude[match(ctar$date.reported, mora_ts$date.reported)]
  checksd <- table(ctar$consult.type, ctar$exclude)[, 2]/table(ctar$consult.type)
  check <- rbind(check, c(sdev[i], checksd[1:2]))
}

plot(check$sd, check$prop_contacts, col = "blue", pch = 20, bty = "n", ylim = c(0, 1), 
     ylab = "Proportion excluded", xlab = "Number of standard deviations")
points(check$sd, check$prop_bites, col = "red", pch = 20)
legend("topright", c("Contacts", "Bites"), col = c("Blue", "Red"), pch = 20, bty = "n")
```

Previous work in the Moramanga District showed that low risk contacts with probable or confirmed rabies cases make up approximately 20% of patients reporting to ARMC (Rajeev et al. 2018). Generally, contacts present as clustered cases, so we excluded patients reporting on any dates that had greater than 3 standard deviations above the mean number of patients reporting per day (Figure 3A). We validated this method using the Moramanga ARMC data for which we had details on the type of exposure, and found that setting the threshold to 3 standard deviations (SDs) resulted in approximately 50% of known contacts excluded, with only 2% of non-contacts excluded (Figure S4). For the national data for which a subset of patient forms were explicitly noted to be contacts, we found that our exclusion criteria of 3 SDs identified `r round((ctar_check %$% length(exclude_bycomment[exclude_bycomment == 1 & exclude_bydate == 1]))/length(ctar_check %$% exclude_bycomment[exclude_bycomment == 1])*100, 2)` of known contacts. We further excluded these known contacts which were not identified based on the daily distribution of patients, resulting in the exclusion of approximately `r round((ctar_check %$% length(exclude_bycomment[exclude_bycomment == 1 | exclude_bydate == 1]))/nrow(ctar_check)*100, 2)`% of patient records from the national data. We also compared this method to assuming that 20% of total bites at the district level were contacts.

<br>


```{r district level exposures, fig.cap = "Figure 4"}
## districts that are non-reporter and data not available yet CTAR
mada_district@data %>%
select(district = mdg_dis_co, dist_name = district, pop = pop2015adj, ttimes_weighted_dist = ttimes_weighted, 
       dist_catch = CTAR, exclude, color) -> covars

ctar_check %>% 
  filter(exclude_bydate == 0, exclude_bycomment == 0) %>% # exclude contacts
  mutate_at(vars(starts_with("date")), funs(ymd(.))) %>% # format dates
  group_by(year = year(date_de_consultation), district, id_ctar) %>% # group by year and district
  summarize(n = n()) %>% # get count of exposures
  left_join(covars) %>% # add pop + ttimes + reporting
  left_join(clinic_reporting) %>%   # add reporting by clinic + year
  filter(exclude == 0, prop > 0.25) %>% ## filter out excluded catchments and ones with < 25% reporting
  group_by(district, year) %>%
  mutate(bites = n/prop) %>%
  summarise(bites = sum(bites, na.rm = TRUE)) %>%
  left_join(covars) -> exps

col_vals <- dist_catchments$color
names(col_vals) <- dist_catchments$mdg_dis_co
  
ggplot(exps, aes(x = reorder(dist_name, ttimes_weighted_dist), y = bites/pop*1e5, color = district)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  scale_color_manual(values = col_vals) + 
  ylab("Annual bites per 100k") +
  xlab("") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

exps %>%
  group_by(district) %>%
  summarise(bites = mean(bites), n = n()) %>%
  left_join(covars) -> exps_dist
```

After excluding contacts and correcting for undersubmission of forms, our final dataset consisted of estimates of average bite incidence for `r nrow(exps_dist)` districts from `r length(unique(exps_dist$dist_catch))` catchments (Figure 4). 

<br> 


### Model of reported bites as a function of travel time
We modeled bites as a function of travel times as follows:
$$ 
  \mu = exp(\beta_{t}T + \beta_0)P 
$$
where $mu$ is the expected number of bites given travel times and population for a given location. In this way, we can model the impact of travel time on incidence as 
$exp(\beta_{t}T + \beta_0)$ gives an estimate of incidence and multiplying by the population size gives the expected number of bites, so that we can fit this model to the number of bites in each location.

We then estimate the likelihood of observing the bites at the district level where bites are a poisson distribution around the mean $\mu_{d}$, given $\beta_t$, the effect of travel times of reported bites and $\beta_0$, the model intercept.

We fit this to our available data in three ways:
1) the commune data available at the moramanga district, where we fit to $mu_j$
2) The district data available nationally
3) To compare estimates from 1 directly to the national data, the district data but where $mu_d$ is the sum of the travel time effect at the commune level, i.e.:

$$ 
  \mu_{d} = \sum \limits_{j=1}^jexp(\beta_{t}T_j + \beta_0)P_j 
$$

 As travel times are correlated with human population size (Figure Z), we also compared how well bites were predicted by human population size alone for these different models (replacing $Tj$ with log-transformed population in $j$ to avoid squared terms), as a test of whether the observed patterns could be predicted by bite incidence scaling with population size alone. We also looked at how well distance from the closest ARMC (rather than travel times) predicted bites as an alternative proxy for access. 

<br>

### Estimation of burden and reporting 
We used our model to predict average annual bite incidence for all 114 districts in Madagascar, and estimated average reporting of rabid exposures and deaths due to rabies given this and assumptions about rabies exposures.

TO DO: Instead of reporting calculate as incidence of deaths here!!
We calculated the expected reporting of rabid exposures ($\overline\rho$) given bite incidence as predicted by our model($\mu$) as:
$$
  \overline\rho = \frac{\mu \times p_{rabid}}{R}
$$
or the fraction of incidence due to rabid exposures ($\mu \times p_{rabid}$) divided by the total rabies exposure incidence ($r$) for a range of estimated rabies incidence and $p_{rabid}$. We look at the range of $p_{rabid}$ reported in Rajeev et al. 2018 for data from the Moramanga District (0.2 - 0.6). where the proportion of reported bites that are rabies exposures ($p_{rabid}$) are defined as:
$$
           p_{rabid}=
            \begin{cases}
            x, & \text{if}\ \frac{R \times \rho_{max}}{B} > x \\
            \frac{R \times \rho_{max}}{B}, & \text{otherwise}
            \end{cases}
$$
<br>

such that rabid reported bites (i.e. $p_{rabid} \times B_i$) cannot exceed the expected number of human exposures given maximum reporting (i.e. $R_i \times \rho_{max}$). $\rho_{max}$ is taken from the Moramanga ARMC data for Moramanga Ville, the commune with the ARMC (i.e. the area with the minimum travel time in the district, on average *xx* minutes). 

<br>

To generate $R$, the rabies incidence in dogs in the absence of any vaccination, $r$, is  multiplied by the estimated dog population in the commune ($D_i$) and the exposure rate per rabid dogs ($p_{exp}$ = 0.39 persons exposed per rabid dog)(Hampson et al. 2018). We use a human:dog ratio (HDR) of 5 to generate our maximum expected incidence and an HDR of 25 for our minimum expected incidence. As there is little data on dog populations in Madagascar, this range of HDRs encompasses a wide range observed across Africa (cite!).

To estimate the average number of deaths for each commune, we extended the above framework into a stochastic framework as follows (TO DO: take neg bin around min and max for RI instead):
$$
deaths_i = (R_i - p_{rabid}B_i) \times p_{death}
$$
where $R_i$ is drawn from a uniform distribution between the minimum and maximum expected number of human exposures for each location and $B_i$, the number of reported bites, is drawn from a poisson distribution with the mean predicted number of bites from the travel time model. We constrain $p_rabid$ as in Equation N, and we assume that all rabies exposures reported to an ARMC receive and complete PEP, and PEP is completely effective at preventing death due to rabies. The probability of death in the absence of PEP is taken from cite GAVI/Joel paper.  
<br>

### Strategically expanding PEP access
Given limited resources and capacity of clinics to provision PEP, we developed a framework to look at the incremental benefit of expanding PEP provisioning to additional ARMC. Starting with the current locations, we added one clinic and recalculated the proportion of people living < 3 hours away from a clinic for the country. We added the clinic which minimized this metric, and then repeated the process iteratively, ranking clinics and adding the top clinic sequentially. We calculate burden for the given clinic locations and look at the incremental reduction in burden as each clinic is added.
  
### Sensitivity analyses for burden estimates 
- R (increasing or decreasing with pop) (min + max)
- P-rabid min and max
- Probability of death min and max
- Look at change in raw # of deaths and also change in burden by scenarios
  
<br>

## RESULTS 

### Models of bites as a function of travel times
```{r likelihood of observing moramanga data @ commune level, fig.cap = "Figure 5A"}
library(boot)

get.likelihood.bites <- function(bites, covar, pop, params) {
  beta <- params[1]
  intercept <- params[2]
  exp_bites <- inv.logit(beta*covar + intercept)*pop
  return(-sum(dpois(round(bites), lambda = exp_bites, log = TRUE)))
}

get.likelihood.mora <- function(commune, params) {
  # To test likelihood function
  # commune = comm_data
  # district = exps_dist
  # params = c(1e-6, 0.1)
  B_ttimes <- params[1]
  B_0 <- params[2]
  commune %>%
      mutate(bites_mu = inv.logit(B_ttimes*ttimes_weighted + B_0)*pop) -> sum_bites
  return(-sum(dpois(round(sum_bites$), lambda = sum_bites$bites_mu, log = TRUE)))
}

get.likelihood.mada <- function(commune, district, params) {
  # To test likelihood function
  # commune = comm_data
  # district = exps_dist
  # params = c(1e-6, 0.1)
  B_ttimes <- params[1]
  B_0 <- params[2]
  commune %>%
      filter(exclude == 0) %>%
      group_by(mdg_dis_co) %>%
      mutate(bites = inv.logit(B_ttimes*ttimes_weighted + B_0)*pop) %>%
      summarize(sum_bites = sum(bites)) %>%
      left_join(select(district, district, dist_bites = bites), 
                by = c("mdg_dis_co" = "district")) %>%
      filter(!is.na(dist_bites)) -> sum_bites
  return(-sum(dpois(round(sum_bites$dist_bites), lambda = sum_bites$sum_bites, log = TRUE)))
}
get.likelihood.dist <- function(district, params) {
  # To test likelihood function
  # commune = comm_data
  # district = exps_dist
  # params = c(1e-6, 0.1)
  B_ttimes <- params[1]
  B_0 <- params[2]
  district %>%
      filter(exclude == 0) %>%
      mutate(exp_bites = inv.logit(B_ttimes*ttimes_weighted_dist + B_0)*pop) -> district
  return(-sum(dpois(round(district$exp_bites), lambda = round(district$bites), log = TRUE)))
}

### Moramanga model ###
mora_pars <- optim(par = c(1e-6, 0.1), get.likelihood.mora, commune = mora_bites, hessian = TRUE)
B_ttimes_mora <- mora_pars$par[1]
B_0_mora <- mora_pars$par[2]

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(mora_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(mora_pars$hessian)

ntest = 1000; testpar = mora_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, mora_pars$par, varcov)
}

B_ttimes_mora_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_mora_CI <- quantile(sim.par[,2],c(0.025,0.975))

### Madagascar model ###
mada_pars <- optim(par = c(1e-6, 0.1), get.likelihood.mada, district = exps_dist,
             commune = comm_data, hessian = TRUE)
B_ttimes_mada <- mada_pars$par[1]
B_0_mada <- mada_pars$par[2]

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(mada_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(mada_pars$hessian)

ntest = 1000; testpar = mada_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, mada_pars$par, varcov)
}

B_ttimes_mada_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_mada_CI <- quantile(sim.par[,2],c(0.025,0.975))

### District parameters
dist_pars <- optim(par = c(1e-6, 0.1), get.likelihood.dist, district = exps_dist,
              hessian = TRUE)
B_ttimes_dist <- dist_pars$par[1]
B_0_dist <- dist_pars$par[2]

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(dist_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(dist_pars$hessian)

ntest = 1000; testpar = dist_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, dist_pars$par, varcov)
}

B_ttimes_dist_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_dist_CI <- quantile(sim.par[,2],c(0.025,0.975))

par_df <- data.frame(model = c("Mada communes", "Moramanga communes", "Mada districts", 
                               "Mada communes", "Moramanga communes", "Mada districts"),
                     par = c("B_ttimes", "B_ttimes", "B_ttimes", "intercept", "intercept",
                             "intercept"),
                     values = c(B_ttimes_mada, B_ttimes_mora, B_ttimes_dist, 
                                B_0_mada, B_0_mora, B_0_dist),
                     upper_CI = c(CI = B_ttimes_mada_CI[2], B_ttimes_mora_CI[2],
                                  B_ttimes_dist_CI[2],
                                  B_0_mada_CI[2], B_0_mora_CI[2], B_0_dist_CI[2]),
                     lower_CI = c(CI = B_ttimes_mada_CI[1], B_ttimes_mora_CI[1],
                                  B_ttimes_dist_CI[1], 
                                  B_0_mada_CI[1], B_0_mora_CI[1], B_0_dist_CI[1]))
kable(par_df, caption = "Table 1: summary of parameter estimates")
ttimes_plot <- seq(0, 15*60, by = 30)
pop_plot <- 1e5

## Mada
par_df <- as.data.frame(list(model = c("Mada communes", "Moramanga communes", "Mada districts"),
                     B_ttimes = c(B_ttimes_mada, B_ttimes_mora, B_ttimes_dist),
                     B_0 = c(B_0_mada, B_0_mora, B_0_dist),
                     B_0_upper = c(B_0_mada_CI[2], B_0_mora_CI[2], B_0_dist_CI[2]),
                     B_0_lower = c(B_0_mada_CI[1], B_0_mora_CI[1], B_0_dist_CI[1]),
                     B_ttimes_upper = c(CI = B_ttimes_mada_CI[2], B_ttimes_mora_CI[2],
                                  B_ttimes_dist_CI[2]),
                     B_ttimes_lower = c(CI = B_ttimes_mada_CI[1], B_ttimes_mora_CI[1],
                                  B_ttimes_dist_CI[1])))

preds <- foreach(i = 1:nrow(par_df), .combine = rbind) %do% {
  bites <- inv.logit(par_df$B_ttimes[i]*ttimes_plot + par_df$B_0[i])*pop_plot
  upper <- inv.logit(par_df$B_ttimes_upper[i]*ttimes_plot + par_df$B_0_upper[i])*pop_plot
  lower <- inv.logit(par_df$B_ttimes_lower[i]*ttimes_plot + par_df$B_0_lower[i])*pop_plot
  return(as.data.frame(list(bites = bites, upper = upper, lower = lower, ttimes = ttimes_plot/60, 
                            model = par_df$model[i])))
}
ggplot(data = preds, aes(x = ttimes, y = bites, color = model)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = model), alpha = 0.5) +

plot(ttimes_plot/60, inv.logit(B_ttimes_mada*ttimes_plot + B_0_mada)*pop_plot, type = "l", bty = "l",
     ylab = "Mean bites per 100k", xlab = "Travel times (hrs)", col = "darkblue")
points(ttimes_plot/60, inv.logit(B_ttimes_mada_CI[1]*ttimes_plot + B_0_mada_CI[1])*pop_plot, type = "l", 
       lty = 2, col = "lightblue")
points(ttimes_plot/60, inv.logit(B_ttimes_mada_CI[2]*ttimes_plot + B_0_mada_CI[2])*pop_plot, type = "l", 
       lty = 2, col = "lightblue")

points(ttimes_plot/60, inv.logit(B_ttimes_mora*ttimes_plot + B_0_mora)*pop_plot, type = "l", col = "red")
points(ttimes_plot/60, inv.logit(B_ttimes_mora_CI[1]*ttimes_plot + B_0_mora_CI[1])*pop_plot, type = "l", 
       lty = 2, col = "pink")
points(ttimes_plot/60, inv.logit(B_ttimes_mora_CI[2]*ttimes_plot + B_0_mora_CI[2])*pop_plot, type = "l",
       lty = 2, col = "pink")

points(ttimes_plot/60, inv.logit(B_ttimes_dist*ttimes_plot + B_0_dist)*pop_plot, type = "l", col = "purple")
points(ttimes_plot/60, inv(B_ttimes_dist_CI[1]*ttimes_plot + B_0_dist_CI[1])*pop_plot, type = "l", 
       lty = 2, col = "lavender")
points(ttimes_plot/60, exp(B_ttimes_dist_CI[2]*ttimes_plot + B_0_dist_CI[2])*pop_plot, type = "l",
       lty = 2, col = "lavender")

legend("topright", c("Mada communes", "Mada districts", "Moramanga communes"), 
       col = c("darkblue", "purple", "red"), 
       lty = c(1, 1, 1), 
       bty = "n")
```

```{r model table, results = "show"}
kable(par_df, caption = "Table 1: summary of parameter estimates")
```

```{r figure 5B, fig.cap="Figure 5B"}
## Data vs. predicted
comm_data %>%
      filter(exclude == 0) %>%
      mutate(bites = exp(B_ttimes_mada*ttimes_weighted + B_0_mada)*pop) %>%
      group_by(mdg_dis_co) %>%
      summarize(sum_bites = sum(bites)) %>%
      left_join(select(exps_dist, district, dist_bites = bites), 
                by = c("mdg_dis_co" = "district")) %>%
      filter(!is.na(dist_bites)) -> sum_bites
sum_bites %$% plot(dist_bites, sum_bites, bty = "n", pch = 20, col = alpha("darkblue", 0.5),
                   xlab = "Observed mean bites", ylab = "Model predicted mean bites", 
                   xlim = c(0, 5000))
abline(a = 0, b = 1, col = "grey", lty = 2)

exps_dist %>%
      mutate(bites_mu = exp(B_ttimes_dist*ttimes_weighted_dist + B_0_dist)*pop) -> check
points(check$bites, check$bites_mu, col = alpha("purple", 0.5), pch = 20)

mora_bites %>%
      mutate(bites_mu = exp(B_ttimes_mora*ttimes_weighted + B_0_mora)*pop) -> check
points(check$bites, check$bites_mu, bty = "n", pch = 20, col = alpha("red", 0.5))
legend("topright", inset = c(-0.1, -0.2),
       c("Mada communes", "Mada districts", "Moramanga communes"), 
       col = c(alpha("darkblue", 0.5), alpha("purple", 0.5), alpha("red", 0.5)), 
       pch = 20, 
       bty = "n", xpd = TRUE)

```

<br> 

We estimated similar parameter values from our commune-level data from the Moramanga ARMC and the district level data from 19 clinics across the country (Table 1, Figure 5A), with reported bite incidence decreasing with travel times to the ARMC. All of the models produced reasonable fits to the data (Figure 5B), however, there was some variation in bite incidence that was not captured by the model. 

#### Model validation
```{r model validation}
## Models
get.likelihood.other <- function(weight, bites, pop, params) {
  B_ttimes <- params[1]
  B_0 <- params[2]
  exp_bites <- inv.logit(B_ttimes*weight + B_0)*pop
  return(-sum(dpois(round(exp_bites), lambda = round(bites), log = TRUE)))
}


## Distance to CTAR
ctar_coords <- cbind(ctar_metadata$LONGITUDE, ctar_metadata$LATITUDE)
district_coords <- coordinates(mada_district)
library(geosphere)
distance_mat <- distm(district_coords, ctar_coords)
dist_min <- apply(distance_mat, 1, min)/1000
exps_dist$dist_min <- dist_min[match(exps_dist$district, mada_district$mdg_dis_co)]

## Unweighted travel times
exps_dist$ttimes_unweighted <- mada_district$study_area[match(exps_dist$district,
                                                              mada_district$mdg_dis_co)]

### District parameters
dist_pars <- optim(par = c(1e-5, -0.1), get.likelihood.other, 
                   weight = exps_dist$dist_min, bites = exps_dist$bites, pop = exps_dist$pop,
                   hessian = TRUE)
B_ttimes_dist <- dist_pars$par[1]
B_0_dist <- dist_pars$par[2]

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(dist_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(dist_pars$hessian)

ntest = 1000; testpar = dist_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, dist_pars$par, varcov)
}

B_ttimes_dist_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_dist_CI <- quantile(sim.par[,2],c(0.025,0.975))

plot(exps_dist$bites, inv.logit(B_ttimes_dist*exps_dist$dist_min+ B_0_dist)*exps_dist$pop)
plot(exps_dist$ttimes_weighted_dist, exps_dist$bites)

### Unweighted
dist_pars <- optim(par = c(1e-3, 0.1), get.likelihood.other, 
                   weight = exps_dist$ttimes_unweighted, bites = exps_dist$bites, 
                   pop = exps_dist$pop,
                   hessian = TRUE)
B_ttimes_dist <- dist_pars$par[1]
B_0_dist <- dist_pars$par[2]

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(dist_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(dist_pars$hessian)

ntest = 1000; testpar = dist_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, dist_pars$par, varcov)
}

B_ttimes_dist_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_dist_CI <- quantile(sim.par[,2],c(0.025,0.975))

plot(exps_dist$bites, exp(B_ttimes_dist*exps_dist$ttimes_unweighted+ B_0_dist))
plot(exps_dist$ttimes_weighted_dist, exps_dist$dist_min)

### Pop
get.likelihood.pop <- function(bites, pop, params) {
  B_ttimes <- params[1]
  B_0 <- params[2]
  exp_bites <- exp(B_ttimes*pop/1e5 + B_0)
  return(-sum(dpois(round(exp_bites), lambda = round(bites), log = TRUE)))
}
pop_pars <- optim(par = c(1e-5, 0.1), get.likelihood.pop, 
                   pop = exps_dist$pop, bites = exps_dist$bites, 
                   hessian = TRUE)
B_pop <- pop_pars$par[1]
B_0_pop <- pop_pars$par[2]
check <- glm(round(bites) ~ pop, data = exps_dist, family = "poisson")
plot(exps_dist$bites, exp(B_pop*exps_dist$pop/1e5 + B_0_pop), pch = 20, col = alpha("red", 0.5))
plot(exps_dist$bites, predict(check, type = "response"), pch = 20, col = alpha("orange", 0.5))
abline(a = 0, b = 1, col = "grey", lty = 2)

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(pop_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(pop_pars$hessian)

ntest = 1000; testpar = pop_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, pop_pars$par, varcov)
}

B_pop_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_pop_CI <- quantile(sim.par[,2],c(0.025,0.975))


## @ commune level
get.likelihood.mada <- function(commune, district, params) {
  # To test likelihood function
  # commune = comm_data
  # district = exps_dist
  # params = c(1e-6, 0.1)
  B_ttimes <- params[1]
  B_0 <- params[2]
  commune %>%
      filter(exclude == 0) %>%
      group_by(mdg_dis_co) %>%
      mutate(bites = exp(B_ttimes*pop/1e5 + B_0)) %>%
      summarize(sum_bites = sum(bites)) %>%
      left_join(select(district, district, dist_bites = bites), 
                by = c("mdg_dis_co" = "district")) %>%
      filter(!is.na(dist_bites)) -> sum_bites
  return(-sum(dpois(round(sum_bites$dist_bites), lambda = sum_bites$sum_bites, log = TRUE)))
}
comm_pars <- optim(par = c(1e-3, 0.1), get.likelihood.mada, 
                   commune = comm_data, district = exps_dist, 
                   hessian = TRUE)
B_ttimes_comm <- comm_pars$par[1]
B_0_comm <- comm_pars$par[2]

## Getting standard errors
# this is how you can get standard errors from optim, but inverting the hessian
se <- sqrt(abs(diag(solve(comm_pars$hessian)))); se

#simulate "standard errors"
varcov <- solve(comm_pars$hessian)

ntest = 1000; testpar = comm_pars$par; sim.par = matrix(NA, ntest, 2)
for (k in 1:ntest) {
  sim.par[k, ] = mvrnorm(1, comm_pars$par, varcov)
}

B_ttimes_comm_CI <- quantile(sim.par[,1],c(0.025,0.975))
B_0_comm_CI <- quantile(sim.par[,2],c(0.025,0.975))

comm_data %>%
      filter(exclude == 0) %>%
      mutate(bites = exp(B_ttimes_comm*pop/1e5 + B_0_comm)) %>%
      group_by(mdg_dis_co) %>%
      summarize(sum_bites = sum(bites)) %>%
      left_join(select(exps_dist, district, dist_bites = bites), 
                by = c("mdg_dis_co" = "district")) %>%
      filter(!is.na(dist_bites)) -> sum_bites
sum_bites %$% plot(dist_bites, sum_bites, bty = "n", pch = 20, col = alpha("darkblue", 0.5),
                   xlab = "Observed mean bites", ylab = "Model predicted mean bites", 
                   xlim = c(0, 5000))
comm_data %>%
      filter(exclude == 0) %>%
      mutate(bites = exp(B_ttimes_mada*ttimes_weighted + B_0_mada)*pop) %>%
      group_by(mdg_dis_co) %>%
      summarize(sum_bites = sum(bites)) %>%
      left_join(select(exps_dist, district, dist_bites = bites), 
                by = c("mdg_dis_co" = "district")) %>%
      filter(!is.na(dist_bites)) -> sum_bites
sum_bites %$% plot(dist_bites, sum_bites, pch = 20, col = alpha("red", 0.5))
abline(a = 0, b = 1, col = "grey", lty = 2)

exps_dist %>%
      mutate(bites_mu = exp(B_ttimes_dist*ttimes_weighted_dist + B_0_dist)*pop) -> check1
points(check1$bites, check1$bites_mu, col = alpha("purple", 0.5), pch = 20)
points(exps_dist$bites, predict(check, type = "response"), pch = 20, col = alpha("orange", 0.5))
abline(a = 0, b = 1, col = "grey", lty = 2)

mora_bites %>%
      mutate(bites_mu = exp(B_ttimes_mora*ttimes_weighted + B_0_mora)*pop) -> check
points(check$bites, check$bites_mu, bty = "n", pch = 20, col = alpha("blue", 0.5))
check <- glm(round(bites) ~ pop, data = mora_bites, family = "poisson")
plot(mora_bites$bites, predict(check, type = "response"), pch = 20, col = alpha("orange", 0.5))
abline(a = 0, b = 1, col = "grey", lty = 2)


## Correlation plot

## Table of fits/parameter results

## Impact of contacts

## Impact of RLE threshold

```


### Estimation of burden and reporting 

```{r reporting by incidence, fig.cap="Figure 6"}
## Mada
bites_100k <- exp(B_ttimes_mada*ttimes_plot + B_0_mada)*pop_plot
R_100k_min <- pop_plot/25*0.01*0.39
R_100k_max <- pop_plot/5*0.01*0.39

plot(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.6 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.6))/R_100k_min,
     type = "l", bty = "n",
     ylab = "Reporting of rabid exposures", xlab = "Travel times (hrs)", col = "darkred")
lines(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.2 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.2))/R_100k_min,
     col = "darkred")
lines(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.6 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.6))/R_100k_max,
     col = "red", lty = 2)
lines(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.2 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.2))/R_100k_max,
     col = "red", lty = 2)
polygon(x = c(ttimes_plot/60, rev(ttimes_plot/60)), 
        y = c(bites_100k*(ifelse(bites_100k*0.2 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.2))/R_100k_min,
             rev(bites_100k*(ifelse(bites_100k*0.2 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.2))/R_100k_max)),
        border = NA, col = alpha("red", 0.2))
polygon(x = c(ttimes_plot/60, rev(ttimes_plot/60)), 
        y = c(bites_100k*(ifelse(bites_100k*0.6 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.6))/R_100k_min,
             rev(bites_100k*(ifelse(bites_100k*0.6 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.6))/R_100k_max)),
        border = NA, col = alpha("red", 0.6))
legend("topright", inset = c(-0.10, 0), c("Max rabies exposures", "Min rabies exposures"), lty = c(2, 1), 
       col = c("red", "darkred"),
       bty = "n", xpd = TRUE)
legend("topright", inset = c(0.01, 0.2), c("p_rabid = 0.2", "p_rabid = 0.6"), border = NA, 
       fill = c(alpha("red", 0.2), alpha("red", 0.6)), bty = "n", xpd = TRUE)
abline(v = max(ttimes_plot[bites_100k*0.6 > R_100k_min])/60, col = "grey", lty = 3)
abline(v = max(ttimes_plot[bites_100k*0.2 > R_100k_max])/60, col = "grey", lty = 3)
```


```{r scale example}
## Comparing scales
comm_data$reporting_min <- get.reporting_burden(pop = comm_data$pop, ttimes = comm_data$ttimes_weighted, 
                                            B_ttimes = B_ttimes_mada, B_0 = B_0_mada,
                                            hdr = 5, p_rabid = 0.2)

comm_data$reporting_max <- get.reporting_burden(pop = comm_data$pop, ttimes = comm_data$ttimes_weighted, 
                                            B_ttimes = B_ttimes_mada, B_0 = B_0_mada,
                                            hdr = 25, p_rabid = 0.6)
comm_data %>%
  group_by(district) %>%
  mutate(pop_total = sum(pop, na.rm = TRUE), prop_pop = pop/pop_total) %>%
  summarize(reporting_min = sum(reporting_min*prop_pop), 
            reporting_max = sum(reporting_max*prop_pop)) %>%
  mutate(reporting_med = (reporting_min + reporting_max)/2,
         type = "summed from commune") -> summed_rep_dist

mada_district@data %>%
  mutate(reporting_min = get.reporting_burden(pop = pop2015un, ttimes = ttimes_weighted, 
                                              B_ttimes = B_ttimes_dist, B_0 = B_0_dist, hdr = 5, 
                                              p_rabid = 0.2), 
         reporting_max = get.reporting_burden(pop = pop2015un, ttimes = ttimes_weighted, 
                                              B_ttimes = B_ttimes_dist, B_0 = B_0_dist, hdr = 25, 
                                              p_rabid = 0.6),
         reporting_med = (reporting_min + reporting_max)/2,
         type = "district level") %>%
  select(district, reporting_min, reporting_max, reporting_med, type) -> rep_comp

rep_comp <- rbind(rep_comp, summed_rep_dist)
rep_comp$ttime <- mada_district$ttimes_weighted[match(rep_comp$district, mada_district$district)]

ggplot(rep_comp, aes(x = reporting_med, y = reorder(district, ttime), 
                              color = type)) +
  ggstance::geom_pointrangeh(aes(xmin = reporting_min, xmax = reporting_max), fatten = 2) 



bites_100k <- exp(B_ttimes_mada*ttimes_plot + B_0_mada)*pop_plot
R_100k_min <- pop_plot/25*0.01*0.39
R_100k_max <- pop_plot/5*0.01*0.39

plot(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.6 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.6))/R_100k_min,
     type = "l", bty = "n",
     ylab = "Reporting of rabid exposures", xlab = "Travel times (hrs)", col = "darkred")
lines(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.2 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.2))/R_100k_min,
     col = "darkred")
lines(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.6 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.6))/R_100k_max,
     col = "red", lty = 2)
lines(ttimes_plot/60, 
     bites_100k*(ifelse(bites_100k*0.2 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.2))/R_100k_max,
     col = "red", lty = 2)
polygon(x = c(ttimes_plot/60, rev(ttimes_plot/60)), 
        y = c(bites_100k*(ifelse(bites_100k*0.2 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.2))/R_100k_min,
             rev(bites_100k*(ifelse(bites_100k*0.2 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.2))/R_100k_max)),
        border = NA, col = alpha("red", 0.2))
polygon(x = c(ttimes_plot/60, rev(ttimes_plot/60)), 
        y = c(bites_100k*(ifelse(bites_100k*0.6 > R_100k_min, 0.98*R_100k_min/bites_100k, 0.6))/R_100k_min,
             rev(bites_100k*(ifelse(bites_100k*0.6 > R_100k_max, 0.98*R_100k_max/bites_100k, 0.6))/R_100k_max)),
        border = NA, col = alpha("red", 0.6))

## Mora
comm_data %>%
  filter(district == "Moramanga") -> comm_level
bites_100k <- exp(B_ttimes_mada*comm_level$ttimes_weighted + B_0_mada)*comm_level$pop
R_100k_min <- comm_level$pop/25*0.01*0.39
R_100k_max <- comm_level$pop/5*0.01*0.39

## district val for Moramanga
## need to merge names
exps_dist %>%
  filter(dist_name == "Moramanga") %>%
  mutate(rep_max = get.reporting_burden(pop = pop, ttimes = ttimes_weighted_dist, 
                                              B_ttimes = B_ttimes_dist, B_0 = B_0_dist, hdr = 25, 
                                              p_rabid = 0.6),
         rep_min = get.reporting_burden(pop = pop, ttimes = ttimes_weighted_dist, 
                                              B_ttimes = B_ttimes_dist, B_0 = B_0_dist, hdr = 5, 
                                              p_rabid = 0.2)) -> dist_level
dist_level %$% points(ttimes_weighted_dist/60, rep_max, col = "red", pch = 20)
dist_level %$% points(ttimes_weighted_dist/60, rep_min, col = "red", pch = 20)
dist_level %$% abline(v = ttimes_weighted_dist/60, col = "red", lty = 2)

```


Generally, estimated reporting of rabies exposures decayed with travel times given model predicted bite incidence and a range of rabies incidence and $p_{rabid}$ (Figure 6). Given our model assumptions, reporting was estimated at the maximum of 0.98 for travel times under 1 hour given the maximum estimated rabies exposure incidence and the minimum estimate of $p_{rabid}$ (the lower range of reporting probabilities), and travel times under 5.5 hours given the minimum estimated rabies exposure incidence and the maximum estimate of $p_{rabid}$ (the upper range of reporting probabilities). 


```{r burden results, fig.cap = "Figure 7", cache = TRUE}
# Incremental analysis ------------------------------------------------------------------------
## District travel times
dist_ttimes <- read.csv("output/district_temp_scenario_20190212_181056.csv", row.names = 1)
comm_ttimes <- read.csv("output/commune_temp_scenario_20190212_182810.csv", row.names = 1)

dist_ttimes <- cbind(dist_catchments$ttimes_weighted, dist_ttimes)
dist_mat <- matrix(NA, nrow(dist_ttimes), ncol(dist_ttimes))
dist_mat[, 1] <- dist_ttimes[, 1]
for (i in 2:ncol(dist_ttimes)){
  dist_mat[, i] <- ifelse(dist_ttimes[, i] < dist_ttimes[, i - 1], dist_ttimes[, i], NA)
}
dist_mat <- as.data.table(dist_mat)
dist_mat$mdg_dis_co <- as.character(mada_district$mdg_dis_co)
dist_mat <- melt(dist_mat, id.vars = "mdg_dis_co", value.name = "ttimes", variable.name = "scenario")
dist_mat$scenario <- as.numeric(gsub("V", "", dist_mat$scenario)) - 1

dist_mat %>%
  drop_na(ttimes) %>%
  left_join(select(mada_district@data, mdg_dis_co, district, pop2015adj)) -> dist_mat

## Commune travel times
comm_ttimes <- cbind(comm_catchments$ttimes_weighted, comm_ttimes)
comm_mat <- matrix(NA, nrow(comm_ttimes), ncol(comm_ttimes))
comm_mat[, 1] <- comm_ttimes[, 1]
for (i in 2:ncol(comm_ttimes)){
  comm_mat[, i] <- ifelse(comm_ttimes[, i] < comm_ttimes[, i - 1], comm_ttimes[, i], NA)
}
comm_mat <- as.data.table(comm_mat)
comm_mat$mdg_cm_ <- mada_communes$mdg_cm_
comm_mat <- melt(comm_mat, id.vars = "mdg_cm_", value.name = "ttimes", variable.name = "scenario")
comm_mat$scenario <- as.numeric(gsub("V", "", comm_mat$scenario)) - 1

comm_mat %>%
  drop_na(ttimes) %>%
  left_join(select(comm_data, mdg_cm_, pop)) -> comm_mat

## Estimate burden
source("R/get.burden.R")
system.time({
  results_pr20_comm <- get.burden(names = comm_mat$mdg_cm_, ttimes = comm_mat$ttimes,
                           pop = comm_mat$pop, scenario = comm_mat$scenario,
                           param_ttimes = B_ttimes_mada,
                           param_intercept = B_0_mada,
                           p_rabid = 0.2, rho_max = 0.98,
                           max_HDR = 25, min_HDR = 5, 
                           dog_rabies_inc = 0.01, human_exp_rate = 0.39, 
                           prob_death = 0.16, nsims = 1000)

results_pr60_comm <- get.burden(names = comm_mat$mdg_cm_, ttimes = comm_mat$ttimes,
                           pop = comm_mat$pop, scenario = comm_mat$scenario,
                           param_ttimes = B_ttimes_mada,
                           param_intercept = B_0_mada,
                           p_rabid = 0.6, rho_max = 0.98,
                           max_HDR = 25, min_HDR = 5, 
                           dog_rabies_inc = 0.01, human_exp_rate = 0.39, 
                           prob_death = 0.16, nsims = 1000)
})

## Filling it in
results_pr20_comm %>%
  complete(scenario, names) %>%
  group_by(names) %>%
  arrange(scenario) %>%
  fill(3:ncol(.), .direction = "down") -> results_pr20_comm

results_pr60_comm %>%
  complete(scenario, names) %>%
  group_by(names) %>%
  arrange(scenario) %>%
  fill(3:ncol(.), .direction = "down") -> results_pr60_comm

system.time({
results_pr20_dist <- get.burden(names = dist_mat$mdg_dis_co, ttimes = dist_mat$ttimes,
                           pop = dist_mat$pop, scenario = dist_mat$scenario,
                           param_ttimes = B_ttimes_dist,
                           param_intercept = B_0_dist,
                           p_rabid = 0.2, rho_max = 0.98,
                           max_HDR = 25, min_HDR = 5, 
                           dog_rabies_inc = 0.01, human_exp_rate = 0.39, 
                           prob_death = 0.16, nsims = 1000)

results_pr60_dist <- get.burden(names = dist_mat$mdg_dis_co, ttimes = dist_mat$ttimes,
                           pop = dist_mat$pop, scenario = dist_mat$scenario,
                           param_ttimes = B_ttimes_dist,
                           param_intercept = B_0_dist,
                           p_rabid = 0.6, rho_max = 0.98,
                           max_HDR = 25, min_HDR = 5, 
                           dog_rabies_inc = 0.01, human_exp_rate = 0.39, 
                           prob_death = 0.16, nsims = 1000)
})

results_pr20_dist %>%
  complete(scenario, names) %>%
  group_by(names) %>%
  arrange(scenario) %>%
  fill(3:ncol(.), .direction = "down") -> results_pr20_dist

results_pr60_dist %>%
  complete(scenario, names) %>%
  group_by(names) %>%
  arrange(scenario) %>%
  fill(3:ncol(.), .direction = "down") -> results_pr60_dist
```


``` {r plotting burden} 
## Group commune results to district level
results_comm <- rbind(results_pr20_comm, results_pr60_comm)
colnames(results_comm) <- gsub("results.", "", colnames(results_comm))
results_comm %>%
  left_join(select(comm_data, mdg_dis_co, mdg_cm_), 
            by = c("names" = "mdg_cm_")) %>%
  group_by(scenario, mdg_dis_co, pr) %>%
  summarize(names = first(mdg_dis_co), 
            deaths_mean = sum(deaths_mean, na.rm = TRUE), 
            deaths_upperCI = sum(deaths_upperCI, na.rm = TRUE),
            deaths_lowerCI = sum(deaths_lowerCI, na.rm = TRUE)) -> results_comm_summarized
results_comm_summarized$model <- "commune"
results_dist <- rbind(results_pr20_dist, results_pr60_dist)
colnames(results_dist) <- gsub("results.", "", colnames(results_dist))
results_dist %>%
  mutate(model = "district") %>%
  select(scenario, names, pr, deaths_mean, deaths_lowerCI, deaths_upperCI, 
         model) %>%
  bind_rows(., results_comm_summarized) -> results_all
results_all %>%
  left_join(select(mada_district@data, district, mdg_dis_co, ttimes_weighted),
            by = c("names" = "mdg_dis_co")) -> results_all 

## Plot national level burden
results_all %>% 
  group_by(scenario, pr, model) %>% 
  summarize(deaths_mean = sum(deaths_mean, na.rm = TRUE), 
            deaths_upperCI = sum(deaths_upperCI, na.rm = TRUE),
            deaths_lowerCI = sum(deaths_lowerCI, na.rm = TRUE)) -> results_natl

## Plotting national level
ggplot(data = results_natl, aes (x = scenario, y = deaths_mean,
                                 color = interaction(model, pr))) +
  geom_line() +
  geom_ribbon(aes(ymin = deaths_upperCI, ymax = deaths_lowerCI, color = NULL, 
                  fill = interaction(model, pr)), alpha = 0.5) +
  scale_color_manual(values = c("district.0.2" = "blue", 
                                "district.0.6" = "darkblue", 
                                "commune.0.2" = "magenta", 
                                "commune.0.6" = "purple"), 
                     name = "model pars") +
  scale_fill_manual(values = c("district.0.2" = "blue", 
                                "district.0.6" = "darkblue", 
                                "commune.0.2" = "magenta", 
                                "commune.0.6" = "purple"), 
                    guide = "none")


## Plotting national level
ggplot(data = results_all, aes(x = deaths_mean, y = reorder(district, ttimes_weighted), 
                               color = scenario, shape = as.factor(pr))) +
  ggstance::geom_pointrangeh(aes(xmin = deaths_lowerCI, xmax = deaths_upperCI), alpha = 0.25,
                             fatten = 2) +
  facet_wrap(~model + as.factor(pr))

## Baseline results
results_all %>% filter(scenario == 0) -> results_all_base
ggplot(results_all_base, aes(y = reorder(district, ttimes_weighted), x = deaths_mean, 
                              color = model, shape = as.factor(pr))) +
  ggstance::geom_pointrangeh(aes(xmin = deaths_lowerCI, xmax = deaths_upperCI), fatten = 2) +
  ylab("") +
  xlab("Average annual deaths") +
  scale_color_manual(values = c("district" = alpha("blue", 0.5), 
                                "commune" = alpha("purple", 0.5)), 
                     name = "Scale") +
  facet_wrap(~ as.factor(pr)) -> p
p + theme(axis.text.y = element_text(margin = margin(t = 10, r = 0, b = 10, l = 0), size = 7)) 

```

```{r doing it from the median, cache=TRUE}
system.time({
  results_comm_med <- get.burden_med(names = comm_mat$mdg_cm_, ttimes = comm_mat$ttimes,
                           pop = comm_mat$pop, scenario = comm_mat$scenario,
                           param_ttimes = B_ttimes_mada,
                           param_intercept = B_0_mada,
                           p_rab_min = 0.2, p_rab_max = 0.6, rho_max = 0.98,
                           max_HDR = 25, min_HDR = 5, 
                           dog_rabies_inc = 0.01, human_exp_rate = 0.39, 
                           prob_death = 0.16, nsims = 1000)
})

## Filling it in
results_comm_med %>%
  complete(scenario, names) %>%
  group_by(names) %>%
  arrange(scenario) %>%
  fill(3:ncol(results_comm_med), .direction = "down") -> results_comm_med

system.time({
results_dist_med <- get.burden_med(names = dist_mat$mdg_dis_co, ttimes = dist_mat$ttimes,
                           pop = dist_mat$pop, scenario = dist_mat$scenario,
                           param_ttimes = B_ttimes_dist,
                           param_intercept = B_0_dist,
                           p_rab_min = 0.2, p_rab_max = 0.6, rho_max = 0.98,
                           max_HDR = 25, min_HDR = 5, 
                           dog_rabies_inc = 0.01, human_exp_rate = 0.39, 
                           prob_death = 0.16, nsims = 1000)
})

results_dist_med %>%
  complete(scenario, names) %>%
  group_by(names) %>%
  arrange(scenario) %>%
  fill(3:ncol(.), .direction = "down") -> results_dist_med

## Group commune results to district level
colnames(results_comm_med) <- gsub("results.", "", colnames(results_comm_med))
results_comm_med %>%
  left_join(select(comm_data, mdg_dis_co, mdg_cm_), 
            by = c("names" = "mdg_cm_")) %>%
  group_by(scenario, mdg_dis_co) %>%
  summarize(deaths_mean = sum(deaths_mean, na.rm = TRUE), 
            deaths_upperCI = sum(deaths_upperCI, na.rm = TRUE),
            deaths_lowerCI = sum(deaths_lowerCI, na.rm = TRUE)) %>%
  rename(names = mdg_dis_co) -> results_comm_summarized
results_comm_summarized$model <- "commune"
colnames(results_dist_med) <- gsub("results.", "", colnames(results_dist_med))
results_dist_med %>%
  mutate(model = "district") %>%
  select(scenario, names, deaths_mean, deaths_lowerCI, deaths_upperCI, 
         model) -> results_dist_med
results_all <- bind_rows(results_dist_med, results_comm_summarized)
results_all %>%
  left_join(select(mada_district@data, district, mdg_dis_co, ttimes_weighted),
            by = c("names" = "mdg_dis_co")) -> results_all 

## Plot national level burden
results_all %>% 
  group_by(scenario, model) %>% 
  summarize(deaths_mean = sum(deaths_mean, na.rm = TRUE), 
            deaths_upperCI = sum(deaths_upperCI, na.rm = TRUE),
            deaths_lowerCI = sum(deaths_lowerCI, na.rm = TRUE)) -> results_natl

## Plotting national level
ggplot(data = results_natl, aes (x = scenario, y = deaths_mean, color = model)) +
  geom_line() +
  geom_ribbon(aes(ymin = deaths_upperCI, ymax = deaths_lowerCI, 
                  color = NULL, fill = model),
              alpha = 0.5) +
  scale_color_manual(values = c("district" = "blue", 
                                "commune" = "purple"), 
                     guide = "none") +
  scale_fill_manual(values = c("district" = "blue", 
                                "commune" = "purple")) +
  guides(color = guide_legend(), 
         fill = guide_legend(override.aes = list(linetype = 1)))

## Plotting national level
ggplot(data = results_all, aes(x = deaths_mean, y = reorder(district, ttimes_weighted), 
                               color = scenario)) +
  ggstance::geom_pointrangeh(aes(xmin = deaths_lowerCI, xmax = deaths_upperCI), alpha = 0.25,
                             fatten = 2) +
  facet_wrap(~model)

## Baseline results
results_all %>% filter(scenario == 0) -> results_all_base
ggplot(results_all_base, aes(y = reorder(district, ttimes_weighted), x = deaths_mean, 
                              color = model)) +
  ggstance::geom_pointrangeh(aes(xmin = deaths_lowerCI, xmax = deaths_upperCI), fatten = 2) +
  ylab("") +
  xlab("Average annual deaths") +
  scale_color_manual(values = c("district" = alpha("blue", 0.5), 
                                "commune" = alpha("purple", 0.5)), 
                     name = "Scale") -> p
p + theme(axis.text.y = element_text(margin = margin(t = 10, r = 0, b = 10, l = 0), size = 7)) 


```

When we estimate burden of deaths stochastically within this range of incidence and given our high and low estimates of proportion of reported bites that are rabid, we see that burden of deaths also decreases with travel times (Figure 7, results presented aggregated at the district level). Overall, we estimate average annual deaths between .... **Also estimate deaths averted here!**. 

When we compare our burden estimates at the district vs. the commune level (summed to district), we see that while overall, the estimates are very similar (Fig NA), at low travel times, calculating burden at the district level results in an assumption of maximum reporting for the whole district, which assumes very low burden.

### Expanding access to PEP

```{r scenario analysis}
## new ctar
expanded <- read.csv("output/incremental_ARMC_nofilter.csv")
dist_ttimes <- read.csv("output/district_temp_scenario_20190212_181056.csv", row.names = 1)
comm_ttimes <- read.csv("output/commune_temp_scenario_20190212_182810.csv", row.names = 1)

dist_burden_min <- apply(dist_ttimes, 2, function(x) get.reporting_burden(pop = mada_district$pop2015adj, ttimes = x, B_ttimes = B_ttimes_dist, B_0 = B_0_dist, hdr = 25, p_rabid = 0.6, type = "burden"))
dist_burden_max <- apply(dist_ttimes, 2, function(x) get.reporting_burden(pop = mada_district$pop2015adj, ttimes = x, B_ttimes = B_ttimes_dist, B_0 = B_0_dist, hdr = 5, p_rabid = 0.2, type = "burden"))

comm_burden_min <- apply(comm_ttimes, 2, function(x) get.reporting_burden(pop = mada_communes$MDG__201, ttimes = x, B_ttimes = B_ttimes_mada, B_0 = B_0_mada, hdr = 25, p_rabid = 0.6, type = "burden"))
comm_burden_max <- apply(comm_ttimes, 2, function(x) get.reporting_burden(pop = mada_communes$MDG__201, ttimes = x, B_ttimes = B_ttimes_mada, B_0 = B_0_mada, hdr = 5, p_rabid = 0.2, type = "burden"))

## Decrease in burden over times proportional
plot(colSums(comm_burden_min, na.rm = TRUE)/sum(comm_burden_min[,1], na.rm = TRUE), type = "l", col = "blue", bty = "n", ylim = c(0, 1), xlab = "# Additional ARMC", 
     ylab = "Proportion of deaths compared to baseline ")
lines(colSums(dist_burden_min, na.rm = TRUE)/sum(dist_burden_min[, 1], na.rm = TRUE),
      col = "purple")
lines(colSums(comm_burden_max, na.rm = TRUE)/sum(comm_burden_max[, 1], na.rm = TRUE), 
     type = "l", col = "blue")
lines(colSums(dist_burden_max, na.rm = TRUE)/sum(dist_burden_max[, 1], na.rm = TRUE), col = "purple")

## Decrease in burden over times absolute
plot(colSums(comm_burden_min, na.rm = TRUE), type = "l", col = "blue", bty = "n",
     ylim = c(0, 1500), xlab = "# Additional ARMC",
     ylab = "Number of deaths")
lines(colSums(dist_burden_min, na.rm = TRUE), col = "purple")
lines(colSums(comm_burden_max, na.rm = TRUE), type = "l", col = "blue")
lines(colSums(dist_burden_max, na.rm = TRUE), col = "purple")

```


### Sensitivity analyses
```{r sensitivity analysis multivariate}
hdr_vals <- c(25, 20, 15, 10, 5)
p_rabid_vals <- c(0.2, 0.3, 0.4, 0.5, 0.6)
rho_max <- c(0.80, 0.85, 0.9, 0.95, 0.9)
library(foreach)

dist_ttimes <- read.csv("output/district_temp_scenario_20190212_181056.csv", row.names = 1)
dist_ttimes <- as.data.table(dist_ttimes)
dist_ttimes$mdg_dis_co <- as.character(mada_district$mdg_dis_co)
dist_ttimes <- melt(dist_ttimes, id.vars = "mdg_dis_co", value.name = "ttimes", variable.name = "scenario")
dist_ttimes$scenario <- as.numeric(gsub("result.", "", dist_ttimes$scenario))
dist_ttimes <- rbind(dist_ttimes, 
                       as.data.frame(list(mdg_dis_co = dist_catchments$mdg_dis_co, scenario = 0,
                                          ttimes = dist_catchments$ttimes_weighted)))
dist_ttimes %>%
  left_join(select(mada_district@data, mdg_dis_co, district, pop = pop2015adj)) -> dist_ttimes

scenario_dist <- 
  foreach(i = 1:length(p_rabid_vals), .combine = rbind) %:%
  foreach(k = 1:length(hdr_vals), .combine = rbind) %:%
  foreach(j = 1:length(rho_max_vals), .combine = rbind) %do% {
  get.reporting_burden(names = dist_ttimes$mdg_dis_co, pop = dist_ttimes$pop, 
                     ttimes = dist_ttimes$ttimes, scenario = dist_ttimes$scenario,
                     B_ttimes = B_ttimes_dist, B_0 = B_0_dist, 
                     hdr = hdr_vals[k], p_rabid = p_rabid_vals[i], 
                     rho_max = rho_max_vals[j], type = "burden")
  }


scenario_dist %>%
  filter(scenario == 0) %>%
  group_by(hdr, p_rabid, rho_max) %>%
  summarize(deaths = sum(deaths, na.rm = TRUE)) -> deaths_multivar
ggplot(data = deaths_multivar, aes(x = p_rabid, y = deaths, color = rho_max)) +
  geom_point() +
  facet_grid(~ hdr)
ggplot(data = filter(scenario_dist, scenario == 0), aes(x = ttimes, y = deaths/pop, color = p_rabid)) +
  geom_point() +
  facet_grid(rho_max ~ hdr)

scenario_dist %>%
  group_by(scenario, hdr, p_rabid, rho_max) %>%
  summarize(deaths = sum(deaths)) -> deaths_scenario
deaths_scenario %>%
  left_join(select(deaths_multivar, hdr, p_rabid, rho_max, deaths_base = deaths)) -> deaths_scenario
ggplot(data = deaths_scenario, aes(x = scenario, y = deaths, color = p_rabid)) +
  geom_point() +
  facet_grid(hdr ~ rho_max, scales = "free_y")

```

```{r scaling w/ pop}
## Pop scaling
pop <- mada_district$pop2015adj
pop <- pop[order(pop, decreasing = FALSE)]
inc100k_max <- 0.01*0.39/5
inc100k_min <- 0.01*0.39/25
pos_scale <- seq(0.01*0.39/25, 0.01*0.39/5, length.out = length(pop))
neg_scale <- seq(0.01*0.39/5, 0.01*0.39/25, length.out = length(pop))
pos <- lm(pos_scale ~ pop) ## use these and constrain
neg <- lm(neg_scale ~ pop) ## use these and constrain

scale_df <- rbind(as.data.frame(list(scale = "neg", 
                                     sf = seq(neg$coefficients[2], 0, length.out = 5),
                                     intercept = inc100k_max)),
                  as.data.frame(list(scale = "pos", 
                                     sf = seq(0, pos$coefficients[2], length.out = 5),
                                     intercept = inc100k_min)))
constrained_inc <- function(slope, intercept, pop, max, min){
  inc <- slope*pop + intercept
  inc[inc >= max] <- max
  inc[inc <= min] <- min
  return(inc)
}
scale_df %>%
  merge(., select(mada_district@data, mdg_dis_co, ttimes_weighted, pop = pop2015adj)) -> scale_df_dist
ggplot(data = scale_df_dist, aes(x = log(pop), 
                            y = constrained_inc(sf, intercept, pop, inc100k_max, inc100k_min)*1e5, 
                            color = sf)) +
  geom_point() +
  geom_hline(yintercept = c(inc100k_max*1e5, inc100k_min*1e5), linetype = 2, color = "grey")

## getting scaling factors 
scenario_scaled <- 
  foreach(i = 1:length(p_rabid_vals), .combine = rbind) %:%
  foreach(k = 1:nrow(scale_df), .combine = rbind) %:%
  foreach(j = 1:length(rho_max_vals), .combine = rbind) %do% {
  get.reporting_burden(names = dist_ttimes$mdg_dis_co, pop = dist_ttimes$pop, 
                     ttimes = dist_ttimes$ttimes, scenario = dist_ttimes$scenario,
                     B_ttimes = B_ttimes_dist, B_0 = B_0_dist, 
                     p_rabid = p_rabid_vals[i], 
                     rho_max = rho_max_vals[j], type = "burden", scale = TRUE, 
                     slope = scale_df$sf[k], intercept = scale_df$intercept[k])
  }

scenario_scaled %>%
  filter(scenario == 0) %>%
  group_by(slope, p_rabid, rho_max) %>%
  summarize(deaths = sum(deaths, na.rm = TRUE)) -> deaths_multivar
ggplot(data = deaths_multivar, aes(x = p_rabid, y = deaths, color = rho_max)) +
  geom_point() +
  facet_grid(~ slope)
ggplot(data = filter(scenario_scaled, scenario == 0),  
       aes(x = ttimes, y = deaths/pop, color = p_rabid)) +
  geom_point() +
  facet_grid(rho_max ~ slope)

scenario_scaled %>%
  group_by(scenario, slope, p_rabid, rho_max) %>%
  summarize(deaths = sum(deaths)) -> deaths_scenario
deaths_scenario %>%
  left_join(select(deaths_multivar, slope, p_rabid, rho_max, deaths_base = deaths)) -> deaths_scenario
ggplot(data = deaths_scenario, aes(x = scenario, y = deaths/deaths_base, color = p_rabid)) +
  geom_point() +
  facet_grid(slope ~ rho_max, scales = "free_y")

```
<br>

## DISCUSSION

### Key findings

### Strengths and Limitations

### Broader context

### Conclusions

## Acknowledgements 

## Supplementary Figures

#### S1
#### S2
#### S3
#### S4
#### S5
#### S6